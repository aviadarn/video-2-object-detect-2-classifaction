apiVersion: apps/v1
kind: Deployment
metadata:
  name: triton-detectron2
  labels:
    app: triton-detectron2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: triton-detectron2
  template:
    metadata:
      labels:
        app: triton-detectron2
    spec:
      nodeSelector:
        node.kubernetes.io/instance-type: gpu
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      containers:
        - name: triton
          image: nvcr.io/nvidia/tritonserver:24.01-py3
          imagePullPolicy: IfNotPresent
          args:
            - tritonserver
            - --model-repository=/models
            - --strict-model-config=true
            - --log-verbose=0
          ports:
            - name: http
              containerPort: 8000
            - name: grpc
              containerPort: 8001
            - name: metrics
              containerPort: 8002
          resources:
            requests:
              cpu: "1000m"
              memory: "4Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "2000m"
              memory: "8Gi"
              nvidia.com/gpu: "1"
          readinessProbe:
            httpGet:
              path: /v2/health/ready
              port: http
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 2
            failureThreshold: 6
          livenessProbe:
            grpc:
              port: 8001
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 2
            failureThreshold: 6
          volumeMounts:
            - name: model-repo
              mountPath: /models
      volumes:
        - name: model-repo
          persistentVolumeClaim:
            claimName: triton-model-repo-pvc
